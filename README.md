# Metrics Examples

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/crillab/metrics-examples/HEAD)

## Introduction

*Metrics* is a Python library for making *rEproducible sofTware peRformance
analysIs in perfeCt Simplicity*.

![*Metrics*' logo.](figures/logo.png)

You can find its source code on [*GitHub*](https://github.com/crillab/metrics),
read its documentation on [*Read the Docs*](https:///metrics.readthedocs.io)
and install it with [*pip*](https://pypi.org/project/crillab-metrics/):

```bash
pip3 install crillab-metrics
```

## Examples of *Metrics*

This repository contains various use cases of *Metrics*, that are distributed
for demonstration purposes.
You may access them through the following table of contents:

- [Analysis of different solver competitions](competitions)
    - [SAT 2019 (campaign in CSV format)](competitions/sat-19)
    - [XCSP 2019 (campaign in evaluation format)](competitions/xcsp-19)
- [Analysis of the performance of COP solvers (using various types of files)](cop-solvers)
- [Analysis of the performance of CSP solvers (using XML data files)](csp-solvers)
- [Analysis of the performance of MIP solvers (using raw output files)](mip-solvers)
- [Analysis of the performance of PB solvers (using raw output files)](pb-solvers)
- [Analysis of the performance of SAT solvers (campaign in custom CSV files)](sat-solvers)
- [Analysis of the performance of subgraph solvers (campaign in reverse CSV format)](subgraph-solvers)
